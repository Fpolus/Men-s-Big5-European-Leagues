{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7575b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from splinter import Browser\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ce1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the team to analyze (capitalize first letter of each word): Manchester City FC\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "premier_league_teams_df = pd.read_csv('../Resources/Premier_league_teams.csv')  # Replace with your CSV file path\n",
    "\n",
    "# Get user inputs for school and year\n",
    "team = input(f'Select the team to analyze (capitalize first letter of each word): ')\n",
    "\n",
    "# Years for analysis\n",
    "year_i = input(f'Starting Year (YYYY format): ')\n",
    "year_f = input(f'Ending Year (type in same year for single year analysis): ')\n",
    "\n",
    "# Create the years integers\n",
    "year_i = int(year_i)\n",
    "year_f = int(year_f)\n",
    "years = range(year_i, year_f + 1)\n",
    "\n",
    "# Create a list for the URLs\n",
    "base_url = 'https://fbref.com'\n",
    "team_url = team.replace(' ', '-')\n",
    "\n",
    "urls = []\n",
    "\n",
    "for year in years:\n",
    "    url = f'{base_url}/en/squads/b8fd03ef/{year}-{year + 1}/{team_url}-Stats'\n",
    "    urls.append(url)\n",
    "    \n",
    "print(f'You selected {team} from years {year_i} through {year_f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chrome browser instance\n",
    "browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to automate browsing for Offense\n",
    "combined_data = []\n",
    "\n",
    "# Visit each year the url list\n",
    "for url in urls:  \n",
    "    \n",
    "    # Visit the page and create the soup object\n",
    "    browser.visit(url)\n",
    "    time.sleep(5)\n",
    "    browser.is_element_present_by_id('matchlogs_for', wait_time=5)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Scrape the offensive table from the page\n",
    "    table = soup.find('table', {'class': 'stats_table sortable min_width now_sortable sticky_table eq1 re1 le1', 'id': 'matchlogs_for'})\n",
    "    \n",
    "    # Execute JavaScript to stop further page loading\n",
    "    browser.execute_script(\"window.stop();\")\n",
    "    \n",
    "    # Extract data from the table\n",
    "    data_list = []\n",
    "\n",
    "    # Iterate through the rows in the table body\n",
    "    for row in table.find('tbody').find_all('tr'):\n",
    "        # Extract the 'Date' from the <th> with scope 'row' and class 'left'\n",
    "        date_elem = row.find('th', {'scope': 'row', 'class': 'left'})\n",
    "        date = date_elem.get_text() if date_elem else None\n",
    "\n",
    "        # Other columns extracted from <td> elements\n",
    "        columns = [cell.get_text() for cell in row.find_all('td')]\n",
    "\n",
    "        # Insert 'date' into the beginning of the columns list if it exists\n",
    "        if date:\n",
    "            columns.insert(0, date)\n",
    "\n",
    "        # Append the row data to the list\n",
    "        data_list.append(columns)\n",
    "\n",
    "    combined_data.extend(data_list)\n",
    "\n",
    "# Define columns including 'Notes'\n",
    "columns = ['date', 'start_time', 'comp', 'round', 'dayofweek', 'venue', 'result', 'goals_for', 'goals_against', 'opponent', 'xg_for', 'xg_against', 'possession', 'attendance', 'captain', 'formation', 'referee', 'match_report', 'Notes']\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "team_df = pd.DataFrame(combined_data, columns=columns)\n",
    "\n",
    "\n",
    "team_df.to_csv('../Resources/Man_City2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
